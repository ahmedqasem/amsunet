{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# AMS-UNet\n",
    "This notebook contains the code for code for training and testing the AMS-UNET model, in order to start training the assumption is the data pre-processing is already compleyed\n",
    "\n",
    "before starting create the following folders in the root folder:\n",
    "```\n",
    "- AMSUNET: root folder\n",
    "    |\n",
    "    |_ data \n",
    "    |   |_ train: folder for training data\n",
    "    |   |   |_ image: folder contains training images\n",
    "    |   |   |_ label: folder contains training masks\n",
    "    |   |\n",
    "    |   |_ test: folder for testing data\n",
    "    |   |   |_ image: folder contains testing images\n",
    "    |   |   |_ label: folder contains testing masks\n",
    "    |   |\n",
    "    |   |_ predictions: folder to save the predicted masks\n",
    "    |\n",
    "    |_ trained_models\n",
    "    |   |_ <trained_model_name>.hdf5: trained model file\n",
    "    |\n",
    "    |_ experiments\n",
    "    |   |_ postprocessed_predictions: folder for saving the postprocessed images\n",
    "    |   |_ raw_analysis: folder for raw experiment analysis\n",
    "    |       |_ <file>.csv: CSV containing raw metrics\n",
    "    |\n",
    "    |_ ams_uset_notebook.ipynb\n",
    "    |\n",
    "    |_ postprocessing.py\n",
    "    |\n",
    "    |_ metrics.py\n",
    "    |\n",
    "    |_ model.py\n",
    "        \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Libraries\n",
    "\n",
    "Import necessary Libraries and necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from model import unet\n",
    "from data import trainGenerator, testGenerator, saveResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup Training Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the height of the input images\n",
    "im_height = 512\n",
    "# Define the width of the input images\n",
    "im_width = 512\n",
    "\n",
    "\n",
    "# Path to the folder containing training data (images and labels)\n",
    "train_folder = './data/train'\n",
    "# Path to the folder where trained models will be saved\n",
    "models_folder = './trained_models'\n",
    "model_name = 'model1.hdf5'\n",
    "\n",
    "\n",
    "# Number of epochs for training (how many complete passes through the training data)\n",
    "epochs = 2\n",
    "# Batch size for training (number of samples processed before the model updates)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the number of samples in a directory\n",
    "def count_samples(data_path, subfolder):\n",
    "    # Get the path to the specific subfolder (e.g., 'image' or 'label')\n",
    "    folder_path = os.path.join(data_path, subfolder)\n",
    "    # Count the number of files in the directory\n",
    "    return len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the total number of images in the training folder\n",
    "total_samples = count_samples(train_folder, 'image')\n",
    "\n",
    "# Dynamically calculate steps per epoch\n",
    "# Steps per epoch is the number of batches required to process all training samples\n",
    "steps_per_epoch = total_samples // batch_size\n",
    "if total_samples % batch_size != 0:\n",
    "    steps_per_epoch += 1  # Add an extra step if there are leftover samples in the batch\n",
    "\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation parameters for the training generator\n",
    "data_gen_args = dict(\n",
    "    rotation_range=0.2,         # Randomly rotate images within a range of ±20%\n",
    "    width_shift_range=0.05,     # Randomly shift the image width by ±5% of the total width\n",
    "    height_shift_range=0.05,    # Randomly shift the image height by ±5% of the total height\n",
    "    shear_range=0.05,           # Apply random shearing transformations within ±5% range\n",
    "    zoom_range=0.05,            # Randomly zoom in/out on images within ±5% range\n",
    "    horizontal_flip=True,       # Randomly flip images horizontally\n",
    "    fill_mode='nearest'         # Fill any gaps in transformed images using nearest neighbor pixels\n",
    ")\n",
    "\n",
    "# Create a data generator for training\n",
    "myGene = trainGenerator(\n",
    "    batch_size=batch_size,          # Number of images per batch (defined as `batch_size`)\n",
    "    train_path=train_folder,        # Path to the folder containing training data (set to `train_folder`)\n",
    "    image_folder='image',           # Subfolder name containing training images ('image')\n",
    "    mask_folder='label',            # Subfolder name containing corresponding labels/masks ('label')\n",
    "    aug_dict=data_gen_args,         # Dictionary of data augmentation parameters (`data_gen_args`)\n",
    "    save_to_dir=None,               # Augmented images will not be saved to any directory\n",
    "    target_size=(im_height, im_width)  # Resize all input images and masks to the specified dimensions (`(im_height, im_width)`)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view one of the images generated by the generator \n",
    "\n",
    "notice how the data augmentation is applied on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch of images and masks from the generator\n",
    "image_batch, mask_batch = next(myGene)\n",
    "\n",
    "# Display the first image and its corresponding mask in the batch\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Display the image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image_batch[0].squeeze(), cmap=\"gray\")  # Use squeeze() to remove extra dimensions\n",
    "plt.title(\"Image\")\n",
    "plt.axis(\"off\")\n",
    "# Display the mask\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask_batch[0].squeeze(), cmap=\"gray\")  # Use squeeze() to remove extra dimensions\n",
    "plt.title(\"Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a U-Net model with the specified input size\n",
    "# Input size is defined as (im_height, im_width, 1), where 1 represents one channel for grayscale images\n",
    "model = unet(input_size=(im_height, im_width, 1))\n",
    "\n",
    "# Define a callback to save the model during training\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    f'{models_folder}/{model_name}',    # Path where the model will be saved\n",
    "    monitor='loss',                     # Monitor the loss during training\n",
    "    verbose=1,                          # Print messages about the saving process\n",
    "    save_best_only=True                 # Save only the model with the best (lowest) loss\n",
    ")\n",
    "\n",
    "# Train the U-Net model using the data generator\n",
    "history = model.fit_generator(\n",
    "    myGene,                                 # The training data generator\n",
    "    steps_per_epoch = steps_per_epoch,      # Number of batches of data per epoch\n",
    "    epochs = epochs,                        # Number of epochs for training\n",
    "    callbacks=[model_checkpoint]            # Use the ModelCheckpoint callback to save the best model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "# If accuracy metric is available\n",
    "if 'accuracy' in history.history:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the testing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the height of the input images for testing\n",
    "im_height = 1024\n",
    "\n",
    "# Define the width of the input images for testing\n",
    "im_width = 1024\n",
    "\n",
    "# Path to the folder containing testing images\n",
    "test_folder = './data/test/image'\n",
    "\n",
    "# Path to save the predicted masks\n",
    "predictions_folder = \"./data/predictions/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model_path = f'{models_folder}/{model_name}'\n",
    "model = unet(input_size=(im_height, im_width, 1))\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Testing Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of images in the training folder\n",
    "total_test_samples = count_samples(test_folder, '')\n",
    "\n",
    "print(f\"Total samples: {total_test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "testGene = testGenerator(test_folder, target_size=(im_height, im_width))\n",
    "\n",
    "# Generate test data and collect file names\n",
    "test_data = list(testGenerator(test_folder, target_size=(512, 512)))\n",
    "# Separate images and file names\n",
    "test_images, file_names = zip(*test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the prediction on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions\n",
    "results = model.predict(testGene, steps=total_test_samples, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 2 predicted masks\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Display the mask\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(results[0,:,:,:].squeeze(), cmap=\"gray\")  # Use squeeze() to remove extra dimensions\n",
    "plt.title(\"Mask 1\")\n",
    "plt.axis(\"off\")\n",
    "# Display the mask\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(results[1,:,:,:].squeeze(), cmap=\"gray\")  # Use squeeze() to remove extra dimensions\n",
    "plt.title(\"Mask 2\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "saveResult(predictions_folder, results, file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessing import gaus_otsu_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder where post-processed masks will be saved\n",
    "postprocessed_masks_folder = './experiments/postprocessed_predictions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gaussian blur and Otsu thresholding on the predicted masks\n",
    "# gaus_otsu_thresh: Function to perform Gaussian blur followed by Otsu thresholding\n",
    "# predictions_folder: Path to the folder containing predicted masks (input folder)\n",
    "# postprocessed_masks_folder: Path to save the post-processed masks (output folder)\n",
    "processed_images = gaus_otsu_thresh(predictions_folder, postprocessed_masks_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 2 predicted masks\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Display the mask\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(processed_images[0], cmap=\"gray\")  # Use squeeze() to remove extra dimensions\n",
    "plt.title(\"Mask 1\")\n",
    "plt.axis(\"off\")\n",
    "# Display the mask\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(processed_images[1], cmap=\"gray\")  # Use squeeze() to remove extra dimensions\n",
    "plt.title(\"Mask 2\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 calculate the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from metrics import find_metrics, tpr, fpr, f_score, iou_score, sensitivity, specificity, accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save folder\n",
    "save_to = './experiments/raw_analysis' # change output folder as needed\n",
    "no_images = total_test_samples\n",
    "csv_file_name = 'metrics.csv'\n",
    "\n",
    "# Load data\n",
    "label_mono_path = postprocessed_masks_folder # folder for the predictions that we need to analyze\n",
    "label_truth_path = './data/test/label/' # ground truth folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Metrics\n",
    "image_list = []\n",
    "TPR = []\n",
    "FPR = []\n",
    "F_SCORE = []\n",
    "IOU = []\n",
    "IOU_SCORE = []\n",
    "SENSITIVITY = []\n",
    "SPECIFICITY = []\n",
    "ACCURACY = []\n",
    "TP = []\n",
    "TN = []\n",
    "FP = []\n",
    "FN = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "predictions = os.listdir(label_mono_path)\n",
    "print('working on {}'.format(label_mono_path))\n",
    "print(predictions)\n",
    "labels = os.listdir(label_truth_path)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prediction, label in zip(predictions, labels):\n",
    "    # print(f'analyzing {prediction}') # optional\n",
    "\n",
    "    total_bg_pxl_truth, total_obj_pxl_truth, tp, tn, fp, fn = find_metrics(label_truth_path + label,\n",
    "                                                                        label_mono_path + prediction)\n",
    "\n",
    "    # Append metrics for each image\n",
    "    image_list.append(prediction)\n",
    "    TP.append(tp)\n",
    "    TN.append(tn)\n",
    "    FP.append(fp)\n",
    "    FN.append(fn)\n",
    "    TPR.append(tpr(tp, total_obj_pxl_truth))\n",
    "    FPR.append(fpr(fp, total_bg_pxl_truth))\n",
    "    F_SCORE.append(f_score(tp, fp, fn))\n",
    "    IOU_SCORE.append(iou_score(label_truth_path + label, label_mono_path + prediction))\n",
    "    SENSITIVITY.append(sensitivity(tp, fn))\n",
    "    SPECIFICITY.append(specificity(fp, tn))\n",
    "    ACCURACY.append(accuracy(tp, fp, tn, fn))\n",
    "\n",
    "    # Append metrics for each image\n",
    "    image_list.append(prediction)\n",
    "    TP.append(tp)\n",
    "    TN.append(tn)\n",
    "    FP.append(fp)\n",
    "    FN.append(fn)\n",
    "    TPR.append(tpr(tp, total_obj_pxl_truth))\n",
    "    FPR.append(fpr(fp, total_bg_pxl_truth))\n",
    "    F_SCORE.append(f_score(tp, fp, fn))\n",
    "    IOU_SCORE.append(iou_score(label_truth_path + label, label_mono_path + prediction))\n",
    "    SENSITIVITY.append(sensitivity(tp, fn))\n",
    "    SPECIFICITY.append(specificity(fp, tn))\n",
    "    ACCURACY.append(accuracy(tp, fp, tn, fn))\n",
    "\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        print('analyzed ', i, ' images')\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Image': image_list,\n",
    "    'TPR': TPR,\n",
    "    'FPR': FPR,\n",
    "    'F-Score': F_SCORE,\n",
    "    'IOU Score': IOU_SCORE,\n",
    "    'Sensitivity': SENSITIVITY,\n",
    "    'Specificity': SPECIFICITY,\n",
    "    'Accuracy': ACCURACY,\n",
    "    'TP': TP,\n",
    "    'TN': TN,\n",
    "    'FP': FP,\n",
    "    'FN': FN\n",
    "})\n",
    "\n",
    "\n",
    "print('average TPR: ', np.average(TPR))\n",
    "print('average FPR: ', np.average(FPR))\n",
    "print('average F-Score: ', np.average(F_SCORE))\n",
    "print('average IOU: ', np.average(IOU))\n",
    "print('average sensitivity: ', np.average(SENSITIVITY))\n",
    "print('average specificity: ', np.average(SPECIFICITY))\n",
    "print('average accuracy: ', np.average(ACCURACY))\n",
    "print('average IOU score: ', np.average(IOU_SCORE))\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(os.path.join(save_to, csv_file_name), index=False)\n",
    "print(f\"Metrics saved to {save_to}/{csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amsunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
